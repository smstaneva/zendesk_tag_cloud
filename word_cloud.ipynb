{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#31708f'><center>Zendesk Tickets Word Cloud </center></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the development environment: \n",
    "- Install Git\n",
    "- Install Anaconda distribution\n",
    "- Install Node.js\n",
    "- Install Postman native app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">In Git Bash</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the working directory:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cd Desktop/JUPYTER_NOTEBOOKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install Newman (command-line collection runner for Postman):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "npm install newman -global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block shows successful run of the command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The User@PC MINGW64 ~/Desktop/JUPYTER_NOTEBOOKS\n",
    "$ npm install newman -global\n",
    "C:\\Users\\smsta\\AppData\\Roaming\\npm\\newman -> C:\\Users\\smsta\\AppData\\Roaming\\npm\\node_modules\\newman\\bin\\newman.js\n",
    "+ newman@5.1.0\n",
    "added 157 packages from 197 contributors in 61.806s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">In Base64</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUTHORIZATION - Basic Authetication and API tokens<br> \n",
    "Use your company email address and Zendesk API key. The credentials must be sent in an Authorization header in the HTTP request. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate a request with basic authentication and API token: \n",
    "- Combine your email address/token with your Zendesk API key with a colon:\n",
    "```svetlana.staneva@eventsforce.com/token: {zendesk_api_key}```\n",
    "- Base64-encode the resulting string:\n",
    "```amRvZUBleGFtcGxlLmNvbTpwYSQkdzByZA==```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">In TextMechanic<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate a lists of numbers (1-3000, 3001-5000, etc.) up to 59046\n",
    "- Create a runner.csv files with a column ticket_id and listing numbers from 1 to 3000, etc.\n",
    "- Move the files to the working directory JUPYTER_NOTEBOOKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">In Postman \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postman Comments Collection<br>\n",
    "The Comments is a Postman collection that lists comments for Zendesk tickets from number 1 to 59046."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new environment: \n",
    "- Click on the Cog icon \n",
    "- Click Add \n",
    "- In Add Environment enter a name for the environment - for instance, Test \n",
    "- Click Add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an active environment:\n",
    "- Click the dropdown menu in the upper right corner of the Postman app to select an active environment (Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request data via GET request: https://eventsforce.zendesk.com/api/v2/tickets/{ticket_id}/comments.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Headers include the base64-encoded string: \n",
    "- In Headers go to Presets > Manage Presets\n",
    "- Add the Authorization and click Add: \n",
    "```Authorization: Basic {base64-encoded-string}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tests add the following line of code:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tests[responseBody] = true;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Comments Collection\n",
    "- Click on Collections > Create New Collection\n",
    "- Enter a name - for instance, Comments and click Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Request in the Collection: \n",
    "- Click on Save As\n",
    "- Select the Collection and click Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the collection locally in the Postman Collection Runner with the runner_head.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the Comments collection: \n",
    "- Click on Collections \n",
    "- Hover over the Comments collection and click on the dots '...' that appear\n",
    "- Click Export and again Export\n",
    "- Save the file on the Desktop\n",
    "- The exported file is COMMENTS.postman_collection.json\n",
    "- Move the file COMMENTS.postman_collection.json to the working directory JUPYTER_NOTEBOOKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">In Git Bash</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Comments collection with the additional runner.csv file of key values (by 3000) and generate report in json."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "newman run COMMENTS.postman_collection.json -d runner.csv -r cli,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case it gives an error 'JavaScript heap out of memory' run the code in the following format:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NODE_OPTIONS=\"--max_old_space_size=2048\" newman run COMMENTS.postman_collection.json -d runner.csv -r cli,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NODE_OPTIONS=\"--max_old_space_size=3072\" newman run COMMENTS.postman_collection.json -d runner.csv -r cli,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or run the Comments collection with the additional runner.csv file of key values (by 1000) and generate report in json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run multiple runs with different runner.csv files, create a name.sh file listing the commands:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "newman run COMMENTS.postman_collection.json -d runner_1000.csv -r cli,json\n",
    "newman run COMMENTS.postman_collection.json -d runner_2000.csv -r cli,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the .sh file:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bash name.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure glob.glob returns a list of files. List all json files in newman folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "file_list = glob.glob('C:/Users/smsta/Desktop/GIT_REPOSITORIES/zendesk_tag_cloud/newman/*.json') \n",
    "for f in file_list:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process multiple files. Parse JSON - convert from JSON to Python. When you open the file specify the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def extract_all():\n",
    "    final_list =[]  \n",
    "    for filename in file_list: \n",
    "        with open(filename, 'r', encoding=\"utf8\") as file: \n",
    "            output_json = json.load(file)\n",
    "            for (k, v) in output_json.items():\n",
    "                if k == \"run\":\n",
    "                    executions_values = v[\"executions\"]\n",
    "                    for ticket in executions_values:\n",
    "                        single_ticket = ticket\n",
    "                        for (k1, v1) in single_ticket.items():\n",
    "                            if k1 == \"assertions\":\n",
    "                                for elem in v1: \n",
    "                                    for (k2, v2) in elem.items():\n",
    "                                        if k2 == 'assertion':\n",
    "                                            res2 = json.loads(v2)\n",
    "                                            for (k3, v3) in res2.items():\n",
    "                                                if k3 == 'comments':\n",
    "                                                    for elem1 in v3:\n",
    "                                                        for (k4, v4) in elem1.items():\n",
    "                                                            if k4 == 'body':\n",
    "                                                                final_list.append(v4)\n",
    "    return(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO NOT TOUCH ORIGINAL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_ticket(element):\n",
    "    values= []\n",
    "    for (k1, v1) in element.items():\n",
    "        if k1 == \"assertions\":\n",
    "            for elem in v1: \n",
    "                for (k2, v2) in elem.items():\n",
    "                    if k2 == 'assertion':\n",
    "                        res2 = json.loads(v2)\n",
    "                        for (k3, v3) in res2.items():\n",
    "                            if k3 == 'comments':\n",
    "                                for elem1 in v3:\n",
    "                                    for (k4, v4) in elem1.items():\n",
    "                                        if k4 == 'body':\n",
    "                                            values_executions = v['executions']\n",
    "                                            values.append(value_executions)\n",
    "    return(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_list = []\n",
    "for ticket in value_executions:\n",
    "        output = extract_text_from_ticket(ticket)\n",
    "        joined_output =' '.join(output)\n",
    "        ticket_list.append(joined_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Optional) if you would like to see the text of the tickets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (k, v) in data.items():\n",
    "    if k == \"run\":\n",
    "        value_executions = v['executions']\n",
    "for element in value_executions: \n",
    "    for (k1, v1) in element.items():\n",
    "        if k1 == \"assertions\":\n",
    "            for elem in v1: \n",
    "                for (k2, v2) in elem.items():\n",
    "                    if k2 == 'assertion':\n",
    "                        res2 = json.loads(v2)\n",
    "                        for (k3, v3) in res2.items():\n",
    "                            if k3 == 'comments':\n",
    "                                for elem1 in v3:\n",
    "                                    for (k4, v4) in elem1.items():\n",
    "                                        if k4 == 'body':\n",
    "                                                print(v4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">In Anaconda Prompt (run as Admin)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install wordcloud package:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "conda install -c conda-forge wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "wordcloud = WordCloud(stopwords=stopwords, \n",
    "                      background_color=\"white\",\n",
    "                      width = 4000,\n",
    "                      height = 2000,\n",
    "                      max_words=200,  \n",
    "                      collocations = False\n",
    "                     ).generate(' '.join(ticket_list))\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOVE TO NEW FILE WHATS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "docs = ticket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_vector=cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ticket_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_list[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
