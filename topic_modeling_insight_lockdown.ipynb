{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644d01df",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('zendesk_txt_lockdown/ticket_59047.txt'), PosixPath('zendesk_txt_lockdown/ticket_59048.txt'), PosixPath('zendesk_txt_lockdown/ticket_59049.txt'), PosixPath('zendesk_txt_lockdown/ticket_59050.txt'), PosixPath('zendesk_txt_lockdown/ticket_59051.txt'), PosixPath('zendesk_txt_lockdown/ticket_59052.txt')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "    \n",
    "all_txt_files =[]\n",
    "#control order of results from iterator\n",
    "for file in sorted(Path(\"zendesk_txt_lockdown\").iterdir()):\n",
    "    all_txt_files.append(file.parent / file.name)\n",
    "print(all_txt_files[:6])\n",
    "    # counts the length of the list\n",
    "len(all_txt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c61be3b7",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is it possible to set up in a single event different bookable items which are charged in different currencies This ticket has been assigned by Round Robin Hi Claire   Thank you for your inquiry Here are the steps outlined on how to activate multiple currency selection  1 Go to Setup gt Finance gt Settings  2 Select Allow currency selection 3 Click Save  As a result on the basket page delegates will be able to select a different currency to pay with   Please let us know if it worked for you or any questions arise   Kind Regards  Svetlana     Svetlana Staneva  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Claire   Further to my previous email you can create a different general price for each bookable item in Setup gt Finance gt Prices When setting up the general price there is a dropdown for currency from which you can select the preferred currency   Set up price for bookable item 1 Go to Setup gt Finance gt Prices  2 Click Add to add a price 3 In Price Descriptor Name enter a name for the price 4 In What it applies to select General Price 5 In Add New Price enter the amount 6 In Currency dropdown select the preferred currency 7 In Date From enter when it starts 8 In Line item description enter a line how it should appear on the basket checkout page 9 Click Save   Once you have the bookable item the general price and you link the price to the bookable item I would recommend making a test registration to see it in action on the basket page   Please let us know if it worked for you or any questions arise   Kind Regards  Svetlana     Svetlana Staneva  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Claire   I would like to follow up if any questions arise or you might need more assistance with this support request   Kind Regards  Svetlana     Svetlana Staneva  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Svetlana       No thanks – please close the ticket       Many thanks       Claire                              This email and attachments are confidential and intended for the addressees only If you are not the intended recipient please immediately notify the sender permanently and securely delete any copies and do not take action with it or in reliance on it Any views expressed are the authors and do not represent those of IOP except where specifically stated IOP takes reasonable precautions to protect against viruses but accepts no responsibility for loss or damage arising from virus infection For the protection of IOPs systems and staff emails are scanned automatically   Institute of Physics Registered charity no 293851 England amp Wales and SCO40092 Scotland Registered Office   Your privacy is important to us For information about how IOP uses your personal data Thank you for letting us know I will close this ticket for now but please feel free to reopen it by responding to this message should any questions arise   Have a peaceful evening   Kind Regards  Svetlana     Svetlana Staneva  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web ',\n",
       " 'This is a followup to your previous request 48021 Help    Hey it’s me again         So I have a question I like the eblast that I have been creating for the events I am wondering if there is a way to create a template within AD HOC that would not have me just hit ADD and have a clutter of eblasts         Does that make sense         Lewis Bingham    IML Security Supply    Graphic Design  Marketing         3106 South Main Street ▪ Salt Lake City Utah 84115 ▪ P 801 4860079 ▪ F 801 4857205 ▪ W   ▪ GSA GS07F0239W    E lewisbinghamimlsscom                          This message is for the designated recipient only and may contain privileged proprietary or otherwise private information If you have received it in error please notify the sender immediately and delete the original Any other use of the email by you is prohibited This ticket has been assigned by Round Robin Hi Lewis  Thank you for sending this along  Im not sure I quite understand your query and am hoping you can elaborate  Are you looking for a way to copy an email template from one event without having to create a new template in the new event  If so unfortunately there isnt a way to send out an email within Eventsforce without using a template  You will need to create a new template and copy the information using the source code ltgt icon          Best   Vuong Nguyen  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Lewis  I was wondering if youve had a chance to review my latest message in regards to your support request  If youd like to provide an update or require more time to work through my latest comment simply reply to this email or go to  and let me know  If I dont hear back from you I will close this ticket within the next few days      Best   Vuong Nguyen  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Lewis  As we have not heard back from you regarding this query on ad hoc emails I will go ahead and close the ticket  If you still require further assistance please feel free to reply to reopen the ticket and I will be happy to help       Best   Vuong Nguyen  Technical Support Specialist  Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web ',\n",
       " '',\n",
       " '1 I am unable to edit the invitation email  this is greyed out  2 This is a wedding and guests will be registering their party of up to 6 people  how do I add a QBI to the guest registration which allows the additional guests to be created as real attendees  I want the main person registering to enter their number of guests then get up to 6 sets of the same question  name and dietary requirements  Thanks This ticket has been assigned by Round Robin Dear Sara  Thank you for your inquiry I will look into this and get back to you as soon as possible     Kind Regards        Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Sara   Thank you for your email  please find my answers below    1 The invitation email has been previously linked to the category  consultant The consultant category isnt currently visible to you as the category isnt active   1In order to unlink it go to Setup gt Event gt Cagegories and enable consultant  2 Then go to Communication gt Invitationsgt Unlink the template and Save  3 Go to Setup gt Event gt Cagegories and disable consultant    2 In order to add QBI quantity bookable items you need to activate this option you can do that by going to Eventgt SettingsgtProperties In Event Options tick the Quantity Bookable Items checkbox and Save There is a setting in this item to book  create real attendees so dont forget to tick this   Please let me know if this helps or if you require further assistance   Best wishes  Martina     Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Martina     Thanks – the first query solution worked perfectly and I can edit the emails     However and I apologise if I am being stupid but where do I find Event gt Settings gt Properties  When I click on Events I don’t get a Settings option and the same for if I click on Setup gt Event     Thanks again  Sara    Hi Sara   My apologies this is my mistake     Let me correct myself   1Go to Website gt Content gt registration pagesgt edit registration contact details  2 Click on  add here and add  quatity bookable item 3 Fill the details and tick the box  shall this create real attendees   Please let me know if this works    Best  Martina     Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  This is actually why I contacted you  I had followed the instructions on your site and done exactly that – set it up in edit registration contact details and also in the category of guest for the event  However when I preview the form and enter a number of guests nothing happens     Also what the registration contact details option for  Do I need to develop the whole registration in that part and again in the category     Thanks again  Sara    Hi Sara  Let me test your registration process  it seems like there is a link missing between what you are trying to achieve and where these contacts are being sent   One moment please      Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Sara  The item is working correctly as per flow   6583  enter email  6553  Registration contacts details  registration contact enters amount of guests into  Additional guests ie 2 gt click proceed Before the registration contact can enter the details for the guest there is a dependancy setup up and they have to answer    Are you able to join us on the 23rd May YES NO if they answer yes the following page opens as many times as many guests were entered into Additional guests   Guest details 6683   \\u200b If they answer no they are redirected to  So sorry you cant make it If you would like to leave a short message for Euan and Celia here please do so  However I believe you dont need these questions  as that will not work  you are basically asking the second attendee to add the third attendee but the structure is  Registration contact registers the guests   \\u200b  FInaly your event isnt marked as  live hence if you are using a personal registration link from an email it wont redirect you to the event unless you live it   Please let me know if this all makes sense   Best wishes  Martina     Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  OK so basically I need to set up the Registration Contact as the landing page – ie first page they come to from their personal link     Does that mean that I need to set up all of the registration questions in Registration Contact and then end with ‘would you like to register any other guests’ and the number  Then edit the Guest attendee form to just be the details I need on the other guests     Sorry I haven’t had to set it up this way before     Thanks  Sara       Hi Sara   No worries    Your landing page is already  registration contact as this is where you are sending your invitations with personal registration link   The below is correct    Registration contact gt ask how many guests they are bringing  which you already have gt then the guest pages opens as many times as the number he entered and he can fill in the details of those guests   Your setup basically have it all  except you dont need to ask these questions on guest page then     Please let me know if this works  Best Martina     Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  OK I will work on this now     Can you help me on how to best test the registration process  Do I have to invite myself or is there another way to do this  The preview does not do the trick    Hi Sara   Yes the best is to send yourself an invitation with the personal registration link   Put the text in template that says click here and then click on hyperlink icon and add personal registration list   Live the event click on the link and test   Please let me know if you come across any issues   Best Martina     Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Sara  I was wondering if youve had a chance to review my latest message in regards to your support request  If youd like to provide an update or require more time to work through my latest comment simply reply to this email or go to  and let me know  If I dont hear back from you I will solve this ticket within the next few days  Kind regards Martina     Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Sara  We havent heard from you since our last communication therefore we assume you may no longer need assistance with this ticket  This ticket will now be closed however please dont hesitate to contact us if you have further questions or concerns simply by replying to this email  Many thanks      Martina Danielova  Technical Support Specialist   Eventsforce Solutions Ltd   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Martina     Thanks for your help sorry I didn’t get back to you  Crazy times intervened     As you can imagine the event has been cancelled but hopefully I will be back working on it again in the future  So please cancel the ticket     Take care  Sara   ',\n",
       " 'Hello   On event 167 I have two delegates which are mixed up can you assist in how I can sort it out   Charlie Watters amp Chris Williams   My contact number is 07843 579610 if it is easier to call me  Thank you   Emma This ticket has been assigned by Round Robin My email address is emmasaundersallianzcouk Hi Emma  Thank you for your message   I will have a look a look at this for you and will get back to you shortly  Thanks Kim     Kim de Vries  Technical Support Team Leader  Eventsforce Solutions Ltd   Working days Wednesday  Friday   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Emma  Just double checking this is for event 167 Distribution Conference 2015 in the Allianz account as I can not see those registrations and the event is 5 years old  Many thanks Kim     Kim de Vries  Technical Support Team Leader  Eventsforce Solutions Ltd   Working days Wednesday  Friday   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Information Classification Internal       Sorry Kim my fault I was looking at the numbers attending Silly me       The number is 878 J              Copyright in this message and any attachments remains with us It is confidential and may be legally privileged If this message is not intended for you it must not be read copied or used by you or disclosed to anyone else Please advise the sender immediately if you have received this message in error Although this message and any attachments are believed to be free of any virus or other defect that might affect any computer system into which it is received and opened it is the responsibility of the recipient to ensure that it is virus free and no responsibility is accepted by Allianz Insurance plc for any loss or damage in any way arising from its use Cornhill Direct is a trading name of Allianz Insurance plc  Pet Plan Ltd Home and Legacy Insurance Services Ltd Allianz Business Services Ltd and Cornhill Solutions Ltd are part of the Allianz UK group of companies Allianz Insurance plc Registered in England number 84638  Registered Office 57 Ladymead Guildford Surrey GU1 1DB Allianz Engineering Inspection Services Ltd Registered in England number 5441840 Registered Office 57 Ladymead Guildford Surrey GU1 1DB UK  Allianz Insurance plc is authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority registration number 121849 Thank you Emma Even in 878 I can not see either of the two people you mentioned  How weird Can you send a screenshot of where you can see them please  Thanks Kim     Kim de Vries  Technical Support Team Leader  Eventsforce Solutions Ltd   Working days Wednesday  Friday   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Information Classification Internal       This is the issue Chris Williams has Charlie Watters email address and can’t set up Charlie Watters due to this Thank you for  your help with this                      Copyright in this message and any attachments remains with us It is confidential and may be legally privileged If this message is not intended for you it must not be read copied or used by you or disclosed to anyone else Please advise the sender immediately if you have received this message in error Although this message and any attachments are believed to be free of any virus or other defect that might affect any computer system into which it is received and opened it is the responsibility of the recipient to ensure that it is virus free and no responsibility is accepted by Allianz Insurance plc for any loss or damage in any way arising from its use Cornhill Direct is a trading name of Allianz Insurance plc  Pet Plan Ltd Home and Legacy Insurance Services Ltd Allianz Business Services Ltd and Cornhill Solutions Ltd are part of the Allianz UK group of companies Allianz Insurance plc Registered in England number 84638  Registered Office 57 Ladymead Guildford Surrey GU1 1DB Allianz Engineering Inspection Services Ltd Registered in England number 5441840 Registered Office 57 Ladymead Guildford Surrey GU1 1DB UK  Allianz Insurance plc is authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority registration number 121849 Ah ok sorry I was looking at registrations not at the invitation list Let me have a look again  Thanks Kim     Kim de Vries  Technical Support Team Leader  Eventsforce Solutions Ltd   Working days Wednesday  Friday   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Hi Emma  I can see that on the 6th March you uploaded a CSV spreadsheet and that seems to have changed the names Do you still have that spreadsheet just so you can double check if the incorrect name was used with this email address CharlesWattersallianzcouk  If you click on the i for this record you can here edit his profile Please change the first name and last name back to Charles Watters and you can then add Chris Williams as a new person to your invitation list if needed  Let me know if you need more help with this  Thanks Kim     Kim de Vries  Technical Support Team Leader  Eventsforce Solutions Ltd   Working days Wednesday  Friday   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web  Information Classification Internal       Hello Kim       Brilliant thank you all done thank you for your help           Kind regards       Emma               Copyright in this message and any attachments remains with us It is confidential and may be legally privileged If this message is not intended for you it must not be read copied or used by you or disclosed to anyone else Please advise the sender immediately if you have received this message in error Although this message and any attachments are believed to be free of any virus or other defect that might affect any computer system into which it is received and opened it is the responsibility of the recipient to ensure that it is virus free and no responsibility is accepted by Allianz Insurance plc for any loss or damage in any way arising from its use Cornhill Direct is a trading name of Allianz Insurance plc  Pet Plan Ltd Home and Legacy Insurance Services Ltd Allianz Business Services Ltd and Cornhill Solutions Ltd are part of the Allianz UK group of companies Allianz Insurance plc Registered in England number 84638  Registered Office 57 Ladymead Guildford Surrey GU1 1DB Allianz Engineering Inspection Services Ltd Registered in England number 5441840 Registered Office 57 Ladymead Guildford Surrey GU1 1DB UK  Allianz Insurance plc is authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority registration number 121849 Great you are very welcome Emma  I will close this ticket for now but please feel free to reopen by replying to this message if you would need more assistance with this  Have a nice day  Kind regards Kim      Kim de Vries  Technical Support Team Leader  Eventsforce Solutions Ltd   Working days Wednesday  Friday   \\u200bUK Support 44 020 3868 5338  US Support 1 2132694914  APAC Support 61 7 3177 7234  Web ',\n",
       " '']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs = []\n",
    "for txt_file in all_txt_files:\n",
    "    with open(txt_file, encoding=\"utf-8\") as f:\n",
    "        txt_file_as_string = f.read()\n",
    "        all_docs.append(txt_file_as_string)\n",
    "all_docs[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a117a",
   "metadata": {},
   "source": [
    "# <font color='#576675'>Tokenize and Clean-up using gensim’s simple_preprocess()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6680594",
   "metadata": {
    "tags": [
     "GENSIM",
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(all_docs))\n",
    "\n",
    "print(data_words[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb174be",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(all_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01b4e4",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "#Create custom list of English stopwords\n",
    "custom_stopwords = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"ain\",\"all\",\"am\",\"an\",\"and\",\"any\",\"are\",\"aren\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\"between\",\"both\",\"but\",\"by\",\"can\",\"couldn\",\"couldn't\",\"d\",\"did\",\"didn\",\"didn't\",\"do\",\"does\",\"doesn\",\"doesn't\",\"doing\",\"don\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\"further\",\"had\",\"hadn\",\"hadn't\",\"has\",\"hasn\",\"hasn't\",\"have\",\"haven\",\"haven't\",\"having\",\"he\",\"her\",\"here\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\"i\",\"if\",\"in\",\"into\",\"is\",\"isn\",\"isn't\",\"it\",\"it's\",\"its\",\"itself\",\"just\",\"ll\",\"m\",\"ma\",\"me\",\"mightn\",\"mightn't\",\"more\",\"most\",\"mustn\",\"mustn't\",\"my\",\"myself\",\"needn\",\"needn't\",\"no\",\"nor\",\"not\",\"now\",\"o\",\"of\",\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\"own\",\"re\",\"s\",\"same\",\"shan\",\"shan't\",\"she\",\"she's\",\"should\",\"should've\",\"shouldn\",\"shouldn't\",\"so\",\"some\",\"such\",\"t\",\"than\",\"that\",\"that'll\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\"these\",\"they\",\"this\",\"those\",\"through\",\"to\",\"too\",\"under\",\"until\",\"up\",\"ve\",\"very\",\"was\",\"wasn\",\"wasn't\",\"we\",\"were\",\"weren\",\"weren't\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"won\",\"won't\",\"wouldn\",\"wouldn't\",\"y\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\",\"could\",\"he'd\",\"he'll\",\"he's\",\"here's\",\"how's\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"let's\",\"ought\",\"she'd\",\"she'll\",\"that's\",\"there's\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"what's\",\"when's\",\"where's\",\"who's\",\"why's\",\"would\",\"able\",\"abst\",\"accordance\",\"according\",\"accordingly\",\"across\",\"act\",\"actually\",\"added\",\"adj\",\"affected\",\"affecting\",\"affects\",\"afterwards\",\"ah\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\"always\",\"among\",\"amongst\",\"announce\",\"another\",\"anybody\",\"anyhow\",\"anymore\",\"anyone\",\"anything\",\"anyway\",\"anyways\",\"anywhere\",\"apparently\",\"approximately\",\"arent\",\"arise\",\"around\",\"aside\",\"ask\",\"asking\",\"auth\",\"available\",\"away\",\"awfully\",\"b\",\"back\",\"became\",\"become\",\"becomes\",\"becoming\",\"beforehand\",\"begin\",\"beginning\",\"beginnings\",\"begins\",\"behind\",\"believe\",\"beside\",\"besides\",\"beyond\",\"biol\",\"brief\",\"briefly\",\"c\",\"ca\",\"came\",\"cannot\",\"can't\",\"cause\",\"causes\",\"certain\",\"certainly\",\"co\",\"com\",\"come\",\"comes\",\"contain\",\"containing\",\"contains\",\"couldnt\",\"date\",\"different\",\"done\",\"downwards\",\"due\",\"e\",\"ed\",\"edu\",\"effect\",\"eg\",\"eight\",\"eighty\",\"either\",\"else\",\"elsewhere\",\"end\",\"ending\",\"enough\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",\"except\",\"f\",\"far\",\"ff\",\"fifth\",\"first\",\"five\",\"fix\",\"followed\",\"following\",\"follows\",\"former\",\"formerly\",\"forth\",\"found\",\"four\",\"furthermore\",\"g\",\"gave\",\"get\",\"gets\",\"getting\",\"give\",\"given\",\"gives\",\"giving\",\"go\",\"goes\",\"gone\",\"got\",\"gotten\",\"h\",\"happens\",\"hardly\",\"hed\",\"hence\",\"hereafter\",\"hereby\",\"herein\",\"heres\",\"hereupon\",\"hes\",\"hi\",\"hid\",\"hither\",\"home\",\"howbeit\",\"however\",\"hundred\",\"id\",\"ie\",\"im\",\"immediate\",\"immediately\",\"importance\",\"important\",\"inc\",\"indeed\",\"index\",\"information\",\"instead\",\"invention\",\"inward\",\"itd\",\"it'll\",\"j\",\"k\",\"keep\",\"keeps\",\"kept\",\"kg\",\"km\",\"know\",\"known\",\"knows\",\"l\",\"largely\",\"last\",\"lately\",\"later\",\"latter\",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"lets\",\"like\",\"liked\",\"likely\",\"line\",\"little\",\"'ll\",\"look\",\"looking\",\"looks\",\"ltd\",\"made\",\"mainly\",\"make\",\"makes\",\"many\",\"may\",\"maybe\",\"mean\",\"means\",\"meantime\",\"meanwhile\",\"merely\",\"mg\",\"might\",\"million\",\"miss\",\"ml\",\"moreover\",\"mostly\",\"mr\",\"mrs\",\"much\",\"mug\",\"must\",\"n\",\"na\",\"name\",\"namely\",\"nay\",\"nd\",\"near\",\"nearly\",\"necessarily\",\"necessary\",\"need\",\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"ninety\",\"nobody\",\"non\",\"none\",\"nonetheless\",\"noone\",\"normally\",\"nos\",\"noted\",\"nothing\",\"nowhere\",\"obtain\",\"obtained\",\"obviously\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"omitted\",\"one\",\"ones\",\"onto\",\"ord\",\"others\",\"otherwise\",\"outside\",\"overall\",\"owing\",\"p\",\"page\",\"pages\",\"part\",\"particular\",\"particularly\",\"past\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"poorly\",\"possible\",\"possibly\",\"potentially\",\"pp\",\"predominantly\",\"present\",\"previously\",\"primarily\",\"probably\",\"promptly\",\"proud\",\"provides\",\"put\",\"q\",\"que\",\"quickly\",\"quite\",\"qv\",\"r\",\"ran\",\"rather\",\"rd\",\"readily\",\"really\",\"recent\",\"recently\",\"ref\",\"refs\",\"regarding\",\"regardless\",\"regards\",\"related\",\"relatively\",\"research\",\"respectively\",\"resulted\",\"resulting\",\"results\",\"right\",\"run\",\"said\",\"saw\",\"say\",\"saying\",\"says\",\"sec\",\"section\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\"sent\",\"seven\",\"several\",\"shall\",\"shed\",\"shes\",\"show\",\"showed\",\"shown\",\"showns\",\"shows\",\"significant\",\"significantly\",\"similar\",\"similarly\",\"since\",\"six\",\"slightly\",\"somebody\",\"somehow\",\"someone\",\"somethan\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\"sorry\",\"specifically\",\"specified\",\"specify\",\"specifying\",\"still\",\"stop\",\"strongly\",\"sub\",\"substantially\",\"successfully\",\"sufficiently\",\"suggest\",\"sup\",\"sure\",\"take\",\"taken\",\"taking\",\"tell\",\"tends\",\"th\",\"thank\",\"thanks\",\"thanx\",\"thats\",\"that've\",\"thence\",\"thereafter\",\"thereby\",\"thered\",\"therefore\",\"therein\",\"there'll\",\"thereof\",\"therere\",\"theres\",\"thereto\",\"thereupon\",\"there've\",\"theyd\",\"theyre\",\"think\",\"thou\",\"though\",\"thoughh\",\"thousand\",\"throug\",\"throughout\",\"thru\",\"thus\",\"til\",\"tip\",\"together\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",\"try\",\"trying\",\"ts\",\"twice\",\"two\",\"u\",\"un\",\"unfortunately\",\"unless\",\"unlike\",\"unlikely\",\"unto\",\"upon\",\"ups\",\"us\",\"use\",\"used\",\"useful\",\"usefully\",\"usefulness\",\"uses\",\"using\",\"usually\",\"v\",\"value\",\"various\",\"'ve\",\"via\",\"viz\",\"vol\",\"vols\",\"vs\",\"w\",\"want\",\"wants\",\"wasnt\",\"way\",\"wed\",\"welcome\",\"went\",\"werent\",\"whatever\",\"what'll\",\"whats\",\"whence\",\"whenever\",\"whereafter\",\"whereas\",\"whereby\",\"wherein\",\"wheres\",\"whereupon\",\"wherever\",\"whether\",\"whim\",\"whither\",\"whod\",\"whoever\",\"whole\",\"who'll\",\"whomever\",\"whos\",\"whose\",\"widely\",\"willing\",\"wish\",\"within\",\"without\",\"wont\",\"words\",\"world\",\"wouldnt\",\"www\",\"x\",\"yes\",\"yet\",\"youd\",\"youre\",\"z\",\"zero\",\"a's\",\"ain't\",\"allow\",\"allows\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"associated\",\"best\",\"better\",\"c'mon\",\"c's\",\"cant\",\"changes\",\"clearly\",\"concerning\",\"consequently\",\"consider\",\"considering\",\"corresponding\",\"course\",\"currently\",\"definitely\",\"described\",\"despite\",\"entirely\",\"exactly\",\"example\",\"going\",\"greetings\",\"hello\",\"help\",\"hopefully\",\"ignored\",\"inasmuch\",\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\"it'd\",\"keep\",\"keeps\",\"novel\",\"presumably\",\"reasonably\",\"second\",\"secondly\",\"sensible\",\"serious\",\"seriously\",\"sure\",\"t's\",\"third\",\"thorough\",\"thoroughly\",\"three\",\"well\",\"wonder\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c614572c",
   "metadata": {},
   "source": [
    "# <font color='#576675'>Build the Bigram, Trigram Models and Lemmatize</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c788bef",
   "metadata": {
    "tags": [
     "GENSIM",
     "SIMPLE_PREPROCESS",
     "SPACY",
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "import spacy\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# !python3 -m spacy download en  # run in terminal once\n",
    "def process_words(texts, \n",
    "                  stop_words=custom_stopwords, \n",
    "                  allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams and Lemmatization\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6342b",
   "metadata": {},
   "source": [
    "# <font color='#576675'>Build the Topic Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9135e8",
   "metadata": {
    "tags": [
     "CORPORA",
     "PPRINT",
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=100,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "#> [(0,\n",
    "#>   '0.017*\"write\" + 0.015*\"people\" + 0.014*\"organization\" + 0.014*\"article\" + '\n",
    "#>   '0.013*\"time\" + 0.008*\"give\" + 0.008*\"first\" + 0.007*\"tell\" + 0.007*\"new\" + '\n",
    "#>   '0.007*\"question\"'),\n",
    "#>  (1,\n",
    "#>   '0.008*\"christian\" + 0.008*\"believe\" + 0.007*\"god\" + 0.007*\"law\" + '\n",
    "#>   '0.006*\"state\" + 0.006*\"israel\" + 0.006*\"israeli\" + 0.005*\"exist\" + '\n",
    "#>   '0.005*\"way\" + 0.004*\"bible\"'),\n",
    "#>  (2,\n",
    "#>   '0.024*\"armenian\" + 0.012*\"bike\" + 0.006*\"kill\" + 0.006*\"work\" + '\n",
    "#>   '0.005*\"well\" + 0.005*\"year\" + 0.005*\"sumgait\" + 0.005*\"soldier\" + '\n",
    "#>   '0.004*\"way\" + 0.004*\"ride\"'),\n",
    "#>  (3,\n",
    "#>   '0.019*\"team\" + 0.019*\"game\" + 0.013*\"hockey\" + 0.010*\"player\" + '\n",
    "#>   '0.009*\"play\" + 0.009*\"win\" + 0.009*\"nhl\" + 0.009*\"year\" + 0.009*\"hawk\" + '\n",
    "#>   '0.009*\"season\"')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee4ae5",
   "metadata": {},
   "source": [
    "# <font color='#576675'>What is the Dominant topic and its percentage contribution in each document</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e156257",
   "metadata": {
    "tags": [
     "PD",
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=all_docs):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573de34",
   "metadata": {},
   "source": [
    "# <font color='#576675'>The most representative sentence for each topic</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97516b40",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b2191",
   "metadata": {},
   "source": [
    "# <font color='#576675'>Word Clouds of Top N Keywords in Each Topic</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3e752",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "# 1. Wordcloud of Top N words in each topic\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=custom_stopwords,\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52a8e4",
   "metadata": {},
   "source": [
    "# <font color='#576675'>Word Counts of Topic Keywords</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37134bad",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "topics = lda_model.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in data_ready for w in w_list]\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16,10), sharey=True, dpi=160)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c85d85",
   "metadata": {},
   "source": [
    "# <font color='#576675'>Sentence Chart Colored by Topic</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce90ffc",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "# Sentence Coloring of N Sentences\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def sentences_chart(lda_model=lda_model, corpus=corpus, start = 0, end = 13):\n",
    "    corp = corpus[start:end]\n",
    "    mycolors = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "\n",
    "    fig, axes = plt.subplots(end-start, 1, figsize=(20, (end-start)*0.95), dpi=160)       \n",
    "    axes[0].axis('off')\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i > 0:\n",
    "            corp_cur = corp[i-1] \n",
    "            topic_percs, wordid_topics, wordid_phivalues = lda_model[corp_cur]\n",
    "            word_dominanttopic = [(lda_model.id2word[wd], topic[0]) for wd, topic in wordid_topics]    \n",
    "            ax.text(0.01, 0.5, \"Doc \" + str(i-1) + \": \", verticalalignment='center',\n",
    "                    fontsize=16, color='black', transform=ax.transAxes, fontweight=700)\n",
    "\n",
    "            # Draw Rectange\n",
    "            topic_percs_sorted = sorted(topic_percs, key=lambda x: (x[1]), reverse=True)\n",
    "            ax.add_patch(Rectangle((0.0, 0.05), 0.99, 0.90, fill=None, alpha=1, \n",
    "                                   color=mycolors[topic_percs_sorted[0][0]], linewidth=2))\n",
    "\n",
    "            word_pos = 0.06\n",
    "            for j, (word, topics) in enumerate(word_dominanttopic):\n",
    "                if j < 14:\n",
    "                    ax.text(word_pos, 0.5, word,\n",
    "                            horizontalalignment='left',\n",
    "                            verticalalignment='center',\n",
    "                            fontsize=16, color=mycolors[topics],\n",
    "                            transform=ax.transAxes, fontweight=700)\n",
    "                    word_pos += .009 * len(word)  # to move the word for the next iter\n",
    "                    ax.axis('off')\n",
    "            ax.text(word_pos, 0.5, '. . .',\n",
    "                    horizontalalignment='left',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=16, color='black',\n",
    "                    transform=ax.transAxes)       \n",
    "\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.suptitle('Sentence Topic Coloring for Documents: ' + str(start) + ' to ' + str(end-2), fontsize=22, y=0.95, fontweight=700)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "sentences_chart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d4094",
   "metadata": {},
   "source": [
    "# <font color='#576675'>What are the most discussed topics in the documents?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b17a9a",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "# Sentence Coloring of N Sentences\n",
    "def topics_per_document(model, corpus, start=0, end=1):\n",
    "    corpus_sel = corpus[start:end]\n",
    "    dominant_topics = []\n",
    "    topic_percentages = []\n",
    "    for i, corp in enumerate(corpus_sel):\n",
    "        topic_percs, wordid_topics, wordid_phivalues = model[corp]\n",
    "        dominant_topic = sorted(topic_percs, key = lambda x: x[1], reverse=True)[0][0]\n",
    "        dominant_topics.append((i, dominant_topic))\n",
    "        topic_percentages.append(topic_percs)\n",
    "    return(dominant_topics, topic_percentages)\n",
    "\n",
    "dominant_topics, topic_percentages = topics_per_document(model=lda_model, corpus=corpus, end=-1)            \n",
    "\n",
    "# Distribution of Dominant Topics in Each Document\n",
    "df = pd.DataFrame(dominant_topics, columns=['Document_Id', 'Dominant_Topic'])\n",
    "dominant_topic_in_each_doc = df.groupby('Dominant_Topic').size()\n",
    "df_dominant_topic_in_each_doc = dominant_topic_in_each_doc.to_frame(name='count').reset_index()\n",
    "\n",
    "# Total Topic Distribution by actual weight\n",
    "topic_weightage_by_doc = pd.DataFrame([dict(t) for t in topic_percentages])\n",
    "df_topic_weightage_by_doc = topic_weightage_by_doc.sum().to_frame(name='count').reset_index()\n",
    "\n",
    "# Top 3 Keywords for each Topic\n",
    "topic_top3words = [(i, topic) for i, topics in lda_model.show_topics(formatted=False) \n",
    "                                 for j, (topic, wt) in enumerate(topics) if j < 3]\n",
    "\n",
    "df_top3words_stacked = pd.DataFrame(topic_top3words, columns=['topic_id', 'words'])\n",
    "df_top3words = df_top3words_stacked.groupby('topic_id').agg(', \\n'.join)\n",
    "df_top3words.reset_index(level=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da5106",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), dpi=120, sharey=True)\n",
    "\n",
    "# Topic Distribution by Dominant Topics\n",
    "ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')\n",
    "ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))\n",
    "tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])\n",
    "ax1.xaxis.set_major_formatter(tick_formatter)\n",
    "ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))\n",
    "ax1.set_ylabel('Number of Documents')\n",
    "ax1.set_ylim(0, 1000)\n",
    "\n",
    "# Topic Distribution by Topic Weights\n",
    "ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')\n",
    "ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))\n",
    "ax2.xaxis.set_major_formatter(tick_formatter)\n",
    "ax2.set_title('Number of Documents by Topic Weightage', fontdict=dict(size=10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74b551",
   "metadata": {},
   "source": [
    "# <font color='#576675'>t-SNE Clustering Chart</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be78b67",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get topic weights and dominant topics ------------\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "# Get topic weights\n",
    "topic_weights = []\n",
    "for i, row_list in enumerate(lda_model[corpus]):\n",
    "    topic_weights.append([w for i, w in row_list[0]])\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)\n",
    "\n",
    "# Plot the Topic Clusters using Bokeh\n",
    "output_notebook()\n",
    "n_topics = 4\n",
    "mycolors = np.array([color for name, color in mcolors.TABLEAU_COLORS.items()])\n",
    "plot = figure(title=\"t-SNE Clustering of {} LDA Topics\".format(n_topics), \n",
    "              plot_width=900, plot_height=700)\n",
    "plot.scatter(x=tsne_lda[:,0], y=tsne_lda[:,1], color=mycolors[topic_num])\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f970f1",
   "metadata": {},
   "source": [
    "# <font color='#576675'>pyLDAVis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ca864",
   "metadata": {
    "tags": [
     "DONE"
    ]
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary=lda_model.id2word)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
